# TransformerDB

TransformerDB is a neural network that ingests _all_ your organization's data and allows you to query it using natural language.

It's the punch line in a [keynote presentation](https://icde2021.gr/keynotes/) by Jimmy Lin at [ICDE 2021](https://icde2021.gr/):

**The Attack of the Muppets: Data Management in the Era of Pretrained Transformers**

Natural language processing and data management have historically existed harmoniously, like tigers and sharks, masters of their domains&mdash;unstructured text and structured data, respectively.
While there have long been go-betweens, for example, work on relation extraction, knowledge graphs, etc., the recent advent of massively-pretrained transformer models such as BERT and related models (collectively, "muppets") threatens this balance.
Examples of the attack of the muppets include demonstration that pretrained models already know much of what's in knowledge graphs such as Wikidata, pretrained table models, and surprising progress on text-to-SQL parsing.
With models such as GPT-3 grabbing all the headlines, it's not a ridiculous proposition (any longer) to claim that "muppets are all you need".
In this talk, I will explore the veracity and implications of this claim, and what it might mean for NLP and data management research moving forward.

[**Slides**](Lin-ICDE2021-keynote.pdf) from the presentation.